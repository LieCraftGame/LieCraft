- key: llama-3.1
  kind: hf
  hf_repo: meta-llama/Llama-3.1-70B-Instruct
  n_gpus: 8
  tp_size: 8
  max_concurrency: 5
- key: llama-3.3
  kind: hf
  hf_repo: meta-llama/Llama-3.3-70B-Instruct
  n_gpus: 8
  tp_size: 8
  max_concurrency: 5
- key: gemma3
  kind: hf
  hf_repo: google/gemma-3-27b-it
  n_gpus: 2
  tp_size: 2
  max_concurrency: 5
- key: gemma3-12
  kind: hf
  hf_repo: google/gemma-3-12b-it
  n_gpus: 2
  tp_size: 2
  max_concurrency: 5
- key: qwen-2.5
  kind: hf
  hf_repo: Qwen/Qwen2.5-32B-Instruct
  n_gpus: 2
  tp_size: 2
  max_concurrency: 5
- key: qwen-3
  kind: hf
  hf_repo: Qwen/Qwen3-32B
  n_gpus: 4
  tp_size: 4
  max_concurrency: 5
- key: deepseek-distilled-qwen
  kind: hf
  hf_repo: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
  n_gpus: 8
  tp_size: 8
  max_concurrency: 5
- key: deepseek-distilled-llama
  kind: hf
  hf_repo: deepseek-ai/DeepSeek-R1-Distill-Llama-70B
  n_gpus: 8
  tp_size: 8
  max_concurrency: 5
- key: gpt-4o
  kind: api
  provider: azure
  max_concurrency: 15
- key: o4-mini
  kind: api
  provider: azure
  max_concurrency: 15
- key: claude-3.7
  kind: api
  provider: anthropic
  max_concurrency: 15
- key: gemini-2.5-flash
  kind: api
  provider: gemini
  max_concurrency: 15